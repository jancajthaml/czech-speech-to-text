{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence tokenization from Wikipedia\n",
    "\n",
    "https://dumps.wikimedia.org/\n",
    "\n",
    "Take all the text from jsons, lower-case it, remove all punctuation, and remove leading/trailing whitespace\n",
    "\n",
    "Tokenize the sentences and write them to a file where each line is one sentence\n",
    "\n",
    "Sentences containing numeric characters are excluded\n",
    "\n",
    "## To Do\n",
    "[ ] remove single char words excpet of ['a', 'i', 'o', 's', 'u', 'v']\n",
    "\n",
    "[ ] remove lines with non defined in alphabet.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# work_dir = '/workspace/data/wikipedia/'\n",
    "work_dir = '/home/jakub/Documents/projekt/databazeknih/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hasNumbers(inputString):\n",
    "    return bool(re.search(r'\\d', inputString))\n",
    "\n",
    "translator = str.maketrans('', '', string.punctuation,)\n",
    "\n",
    "\n",
    "def charFilter (line):\n",
    "    vysledek = ''\n",
    "    for ch in line:\n",
    "        if ch not in ' aábcčdďeéěfghiíjklmnňoópqrřsštťuúůvwxyýzž':\n",
    "            ch = ''\n",
    "        vysledek = vysledek + ch\n",
    "    \n",
    "    \n",
    "    return vysledek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "hodina_tance_a_lasky.epub.txt\n",
      "proces.epub.txt\n",
      "domaci_kucharka.epub.txt\n",
      "slava_stroju_a_mest.epub.txt\n",
      "valka_s_mloky.epub.txt\n",
      "smrt_krasnych_srncu.txt\n",
      "hovory_s_t_g_masarykem.epub.txt\n",
      "oral2013_vert.txt\n",
      "tanecni_hodiny_pro_starsi_a_pokrocile.epub.txt\n",
      "hubeny_nas_nedostanou.epub.txt\n",
      "ceska_inteligence.epub.txt\n",
      "ctyricet_dnu.epub.txt\n",
      "urazeni_a_ponizeni.epub.txt\n",
      "tri_kluci.epub.txt\n",
      "manzelky_prezidentu.epub.txt\n",
      "pet_nedel_v_balone.epub.txt\n",
      "pusinky.epub.txt\n",
      "rur.epub.txt\n",
      "zahradnikuv_rok.epub.txt\n",
      "preprocessed.txt\n",
      "bajecna_leta_pod_psa.epub.txt\n",
      "anglicke_listy.epub.txt\n",
      "kopretiny_pro_zameckou_pani.epub.txt\n",
      "liska_bystrouska.epub.txt\n",
      "holky_z_porcelanu.epub.txt\n",
      "tajemstvi_sametu.epub.txt\n",
      "lovci_mamutu.epub.txt\n",
      "mluviti_stribro.epub.txt\n",
      "santiniho_jazyk.epub.txt\n",
      "rozmarne_leto.epub.txt\n",
      "velky_gatsby.epub.txt\n",
      "hrichy_pro_patera_knoxe.epub.txt\n",
      "tankovy_prapor.epub.txt\n",
      "povidky_o_manzelstvi_a_o_sexu.epub.txt\n",
      "inzerat_na_dum_ve_kterym_uz_nechci_bydlet.epub.txt\n",
      "plachy_milionar_prichazi.epub.txt\n",
      "zakladni_pojmy.epub.txt\n",
      "pan_kdybych_hleda_kamarada.epub.txt\n",
      "zapisky_mladeho_lekare.epub.txt\n",
      "o_nicem_a_o_vsem.epub.txt\n",
      "utek.epub.txt\n",
      "moudrost_starych_cechu.epub.txt\n",
      "povidky_z_jedne_kapsy.epub.txt\n",
      "zpoved_pozivace_opia.epub.txt\n",
      "slavnosti_snezenek.epub.txt\n",
      "povidky_malostranske.epub.txt\n",
      "cekarny_meho_zivota.epub.txt\n",
      "horke_humoresky.epub.txt\n",
      "bajecna_leta_s_klausem.epub.txt\n",
      "leto_jako_kdyz_vysije.epub.txt\n",
      "stare_povesti_ceske_bez_poznamek.epub.txt\n",
      "jak_se_co_dela.epub.txt\n",
      "povidani_o_pejskovi_a_kocicce.epub.txt\n",
      "velke_trapeni.epub.txt\n",
      "kocici_kral.epub.txt\n",
      "kde_je_zakopan_pes.epub.txt\n",
      "kult_stromu_v_zemich_koruny_ceske.epub.txt\n",
      "spalovac_mrtvol.epub.txt\n",
      "dasenka_cili_zivot_stenete.epub.txt\n",
      "klapzubova_jedenactka.epub.txt\n",
      "moderni_domacnost.epub.txt\n",
      "od_cloveka_k_cloveku_i.epub.txt\n",
      "kniha_lesu_vod_a_strani.epub.txt\n",
      "tovarna_na_absolutno.epub.txt\n",
      "broucci.epub.txt\n",
      "novy_epochalni_vylet_pana_broucka.epub.txt\n",
      "leto_s_kovbojem.epub.txt\n",
      "obrazovy_opravnik_obecne_oblibenych_omylu.epub.txt\n",
      "malajsti_pirati.epub.txt\n",
      "biomanzelka.epub.txt\n",
      "mahulena_krasna_panna.epub.txt\n",
      "pribeh_inzenyra_lidskych_dusi.epub.txt\n",
      "basne_z_koncentracniho_tabora.epub.txt\n",
      "pes_baskervillsky.epub.txt\n",
      "o_slunecniku_mesicniku_a_vetrniku.epub.txt\n",
      "cybersecurity.epub.txt\n",
      "andel_na_koleckach.epub.txt\n",
      "krasosmutneni.epub.txt\n",
      "umelohmotny_tripokoj.epub.txt\n",
      "zkroceni_zle_zeny.epub.txt\n",
      "pohadky_andersen.epub.txt\n",
      "za_cinskou_zdi.epub.txt\n",
      "konec_nylonoveho_veku.epub.txt\n",
      "ezopovy_bajky.epub.txt\n",
      "knizka_s_cervenym_obalem.epub.txt\n",
      "roman_pro_zeny.epub.txt\n",
      "ucastnici_zajezdu.epub.txt\n",
      "devatero_pohadek.epub.txt\n",
      "biblecep.txt\n",
      "svejk_1_a_2.epub.txt\n",
      "babicka.epub.txt\n",
      "vec_makropulos.epub.txt\n",
      "kuchyne_a_stul_nasich_predku.epub.txt\n",
      "divci_skolstvi.epub.txt\n",
      "zatah_na_hackery.epub.txt\n",
      "na_vlne_57_metru.epub.txt\n",
      "maj.epub.txt\n",
      "posledni_poklona.epub.txt\n",
      "vychova_divek_v_cechach.epub.txt\n"
     ]
    }
   ],
   "source": [
    "with open(work_dir + 'preprocessed.txt', \"w+\") as out_file:\n",
    "    \n",
    "    for input_file in os.listdir(work_dir):\n",
    "        print(input_file)\n",
    "        str_builder = ''\n",
    "        with open(work_dir + input_file, \"r\") as in_file:\n",
    "            for line in in_file:\n",
    "                words = sent_tokenize(line)\n",
    "\n",
    "                if len(words) < 2:  # Skip 1 word sentences\n",
    "                    continue\n",
    "\n",
    "                \n",
    "                if hasNumbers(line):\n",
    "                    continue\n",
    "\n",
    "                for s in words:\n",
    "                    str_builder += charFilter(s.lower()).strip() + ' '\n",
    "                str_builder = str_builder.strip() + '\\n'\n",
    "\n",
    "                if len(str_builder) < 3:\n",
    "                    continue\n",
    "\n",
    "        \n",
    "        out_file.write(str_builder)\n"
   ]
  },
  {
   "source": [
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('venv')",
   "metadata": {
    "interpreter": {
     "hash": "683ebf348b6c625824b8b2fc279a80723cbfacc89467e803c54a6ddabea43607"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}