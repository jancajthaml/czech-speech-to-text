{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Mozilla CommonVoice CS data for DeepSpeech2\n",
    "\n",
    "## Dowload data\n",
    "https://commonvoice.mozilla.org/cs/datasets\n",
    "\n",
    "untar\n",
    "\n",
    "## Install deps\n",
    "progressbar2\n",
    "sox\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import subprocess\n",
    "import unicodedata\n",
    "from multiprocessing import Pool\n",
    "import progressbar\n",
    "import sox\n",
    "from collections import Counter\n",
    "\n",
    "data_path = 'commonvoice/cv-corpus-6.1-2020-12-11/cs'\n",
    "\n",
    "FIELDNAMES = [\"wav_filename\", \"wav_filesize\", \"transcript\"]\n",
    "SAMPLE_RATE = 16000\n",
    "CHANNELS = 1\n",
    "MAX_SECS = 10\n",
    "PARAMS = None\n",
    "FILTER_OBJ = None\n",
    "SIMPLE_BAR = ['Progress ', progressbar.Bar(), ' ', progressbar.Percentage(), ' completed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counter():\n",
    "    return Counter({'all': 0, 'failed': 0, 'invalid_label': 0, 'too_short': 0, 'too_long': 0, 'imported_time': 0, 'total_time': 0})\n",
    "\n",
    "\n",
    "def init_worker(params):\n",
    "    global FILTER_OBJ  # pylint: disable=global-statement\n",
    "    validate_label = get_validate_label(params)\n",
    "    alphabet = Alphabet(params.filter_alphabet) if params.filter_alphabet else None\n",
    "    FILTER_OBJ = LabelFilter(params.normalize, alphabet, validate_label)\n",
    "\n",
    "def get_validate_label(args):\n",
    "    \"\"\"\n",
    "    Expects an argparse.Namespace argument to search for validate_label_locale parameter.\n",
    "    If found, this will modify Python's library search path and add the directory of the\n",
    "    file pointed by the validate_label_locale argument.\n",
    "    :param args: The importer's CLI argument object\n",
    "    :type args: argparse.Namespace\n",
    "    :return: The user-supplied validate_label function\n",
    "    :type: function\n",
    "    \"\"\"\n",
    "    # Python 3.5 does not support passing a pathlib.Path to os.path.* methods\n",
    "    if 'validate_label_locale' not in args or (args.validate_label_locale is None):\n",
    "        print('WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.')\n",
    "        return validate_label_eng\n",
    "    validate_label_locale = str(args.validate_label_locale)\n",
    "    if not os.path.exists(os.path.abspath(validate_label_locale)):\n",
    "        print('ERROR: Inexistent --validate_label_locale specified. Please check.')\n",
    "        return None\n",
    "    module_dir = os.path.abspath(os.path.dirname(validate_label_locale))\n",
    "    sys.path.insert(1, module_dir)\n",
    "    fname = os.path.basename(validate_label_locale).replace('.py', '')\n",
    "    locale_module = importlib.import_module(fname, package=None)\n",
    "    return locale_module.validate_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _maybe_convert_set(dataset, tsv_dir, audio_dir, filter_obj, space_after_every_character=None, rows=None, exclude=None):\n",
    "    exclude_transcripts = set()\n",
    "    exclude_speakers = set()\n",
    "    if exclude is not None:\n",
    "        for sample in exclude:\n",
    "            exclude_transcripts.add(sample[2])\n",
    "            exclude_speakers.add(sample[3])\n",
    "\n",
    "    if rows is None:\n",
    "        rows = []\n",
    "        input_tsv = os.path.join(os.path.abspath(tsv_dir), dataset + \".tsv\")\n",
    "        if not os.path.isfile(input_tsv):\n",
    "            return rows\n",
    "        print(\"Loading TSV file: \", input_tsv)\n",
    "        # Get audiofile path and transcript for each sentence in tsv\n",
    "        samples = []\n",
    "        with open(input_tsv, encoding=\"utf-8\") as input_tsv_file:\n",
    "            reader = csv.DictReader(input_tsv_file, delimiter=\"\\t\")\n",
    "            idx = 0\n",
    "            for row in reader:\n",
    "                samples.append((os.path.join(audio_dir, row[\"path\"]), row[\"sentence\"], row[\"client_id\"]))\n",
    "                idx += 1\n",
    "                if idx > 5:\n",
    "                    break\n",
    "\n",
    "        counter = get_counter()\n",
    "        num_samples = len(samples)\n",
    "\n",
    "        print(\"Importing mp3 files...\")\n",
    "        pool = Pool(initializer=init_worker, initargs=(PARAMS,))\n",
    "        bar = progressbar.ProgressBar(max_value=num_samples, widgets=SIMPLE_BAR)\n",
    "        for i, processed in enumerate(pool.imap_unordered(one_sample, samples), start=1):\n",
    "            counter += processed[0]\n",
    "            rows += processed[1]\n",
    "            bar.update(i)\n",
    "        bar.update(num_samples)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "\n",
    "        imported_samples = get_imported_samples(counter)\n",
    "        assert counter[\"all\"] == num_samples\n",
    "        assert len(rows) == imported_samples\n",
    "        print_import_report(counter, SAMPLE_RATE, MAX_SECS)\n",
    "\n",
    "    output_csv = os.path.join(os.path.abspath(audio_dir), dataset + \".csv\")\n",
    "    print(\"Saving new DeepSpeech-formatted CSV file to: \", output_csv)\n",
    "    with open(output_csv, \"w\", encoding=\"utf-8\", newline=\"\") as output_csv_file:\n",
    "        print(\"Writing CSV file for DeepSpeech.py as: \", output_csv)\n",
    "        writer = csv.DictWriter(output_csv_file, fieldnames=FIELDNAMES)\n",
    "        writer.writeheader()\n",
    "        bar = progressbar.ProgressBar(max_value=len(rows), widgets=SIMPLE_BAR)\n",
    "        for filename, file_size, transcript, speaker in bar(rows):\n",
    "            if transcript in exclude_transcripts or speaker in exclude_speakers:\n",
    "                continue\n",
    "            if space_after_every_character:\n",
    "                writer.writerow(\n",
    "                    {\n",
    "                        \"wav_filename\": filename,\n",
    "                        \"wav_filesize\": file_size,\n",
    "                        \"transcript\": \" \".join(transcript),\n",
    "                    }\n",
    "                )\n",
    "            else:\n",
    "                writer.writerow(\n",
    "                    {\n",
    "                        \"wav_filename\": filename,\n",
    "                        \"wav_filesize\": file_size,\n",
    "                        \"transcript\": transcript,\n",
    "                    }\n",
    "                )\n",
    "    return rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _maybe_convert_wav(mp3_filename, wav_filename):\n",
    "    if not os.path.exists(wav_filename):\n",
    "        transformer = sox.Transformer()\n",
    "        transformer.convert(samplerate=SAMPLE_RATE, n_channels=CHANNELS)\n",
    "        try:\n",
    "            transformer.build(mp3_filename, wav_filename)\n",
    "        except sox.core.SoxError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_after_every_character=False\n",
    "tsv_dir = data_path\n",
    "audio_dir = data_path + \"/clips\"\n",
    "exclude = []\n",
    "for dataset in [\"test\", \"dev\", \"train\", \"validated\", \"other\"]:\n",
    "    set_samples = _maybe_convert_set(dataset, tsv_dir, audio_dir, space_after_every_character)\n",
    "    if dataset in [\"test\", \"dev\"]:\n",
    "        exclude += set_samples\n",
    "    if dataset == \"validated\":\n",
    "        _maybe_convert_set(\"train-all\", tsv_dir, audio_dir, space_after_every_character,\n",
    "                            rows=set_samples, exclude=exclude)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}